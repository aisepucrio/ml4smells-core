### code_smells.zip

This folder represents the dataset generated by the application after the complete execution of the workflow. The file `code_smells.db` represents the database where the application persisted the responses from the SLM models that classified the Python algorithms. The file `x.sql` demonstrates some queries that can be made to retrieve information from the database.

**Steps:**
1. Extract the zip file.
2. Import the `code_smells.db` file into a DBMS for use.
3. Use the `x.sql` file to perform queries.

---

### extract_code.zip

This folder contains code extraction files using an AST-based approach, aimed at validating the algorithms that PySmell identifies in its dataset and including them in the present study. In general, the algorithms have similar behaviors: the `code.py` file performs method extraction; the `code2.py` performs class extraction; and the `smell.csv` file represents the file containing the reference codes.

**Steps:**
1. Use the `code.py` or `code2.py` script.
2. Download the project (Boto, NLTK, Django, etc.) from which you want to extract the codes that exist in the PySmell [reference](https://github.com/chenzhifei731/Pysmell/tree/master/pysmell/detection/example%20repository/definite%20negative) file.
3. In the PySmell reference files (`long_method.csv` or `long_parameter_list.csv`), select the lines you wish to analyze.
4. Paste the selected lines into the `smell.csv` file.
5. Replace the `file` column with the directory of the respective project downloaded in step 2.
6. Provide the required arguments in the `main` function.

<br>

**Note:** This is one of the most complex processes within this study, due to the way PySmell provided the respective data. Therefore, it is recommended to use a Python script to extract the respective codes directly from the `code_smells.db` database, making it easier to obtain the codes.

**Suggested script:** `experiments/supplementary_algorithms/get_codes_from_db.py`

---

### data.zip

The `data.zip` folder represents the results, from an analytical perspective, obtained after executing the entire workflow. The `.csv` files represent the runs performed by the SML models. Suggested script to extract the results from the database: `extract_codes_from_db.py`.

**Steps:**
1. Ensure the records are present in `code_smells.db`.
2. Run the `extract_codes_from_db.py` script.
3. Run the `update_columns_in_csv_files.py` script.
4. Run the `matriz.py` script.

---

### ML and DL

The `dataset_ml_dl.csv` file represents the data that the DL and ML models used to train the models. The `multilabel.pkl` file is used for running the ML model; to use it, you need to provide data in a structure similar to that used during training, as described in the notebook `MachineLearningMultilabel.ipynb`, and the model will perform the **classification**.

---

### LLM_LPL_explainability.zip

This folder contains the files extracted from `code_smells.db` with the aim of analyzing the **explainability** of the models.

## Artifacts

[Zenodo](https://zenodo.org/records/16315128)
